{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:56.742378300Z",
     "start_time": "2024-01-31T08:22:46.781379300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wintee\\AppData\\Local\\Temp\\ipykernel_24724\\2596381722.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import urllib.request\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from transformer import Transformer\n",
    "from scheduler import TransformerScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[손실 함수 정의]\n",
    "예제는 다중 클래스 분류 문제. 이때 레이블이 정수 형태이므로 손실 함수는 SparseCategoricalCrossentropy 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576a91a72ec088d6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def loss_function(ans, pred):\n",
    "    \"\"\"\n",
    "    다중 클래스 분류 문제를 위한 손실 함수 정의\n",
    "    \n",
    "    :param ans: 해당 데이터의 실제 정답\n",
    "    :param pred: 모델이 생성해낸 예측 레이블\n",
    "    :return: 손실값\n",
    "    \"\"\"\n",
    "    ans = tf.reshape(ans, shape=(-1, MAX_LENGTH - 1))\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(ans, pred)\n",
    "    mask = tf.cast(tf.not_equal(ans, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:56.785379300Z",
     "start_time": "2024-01-31T08:22:56.739378100Z"
    }
   },
   "id": "83f963a7f2de3c71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[데이터 로드]\n",
    "챗봇 데이터를 로드\n",
    "학습 기반 토크나이저 사용을 위해 구두점 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2feef9c408aadea0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Q            A  label\n0           12시 땡!   하루가 또 가네요.      0\n1      1지망 학교 떨어졌어    위로해 드립니다.      0\n2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n4          PPL 심하네   눈살이 찌푸려지죠.      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Q</th>\n      <th>A</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12시 땡!</td>\n      <td>하루가 또 가네요.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1지망 학교 떨어졌어</td>\n      <td>위로해 드립니다.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3박4일 놀러가고 싶다</td>\n      <td>여행은 언제나 좋죠.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3박4일 정도 놀러가고 싶다</td>\n      <td>여행은 언제나 좋죠.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PPL 심하네</td>\n      <td>눈살이 찌푸려지죠.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:57.326378600Z",
     "start_time": "2024-01-31T08:22:56.764378400Z"
    }
   },
   "id": "1650b7db4acef3b9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print(f'샘플의 개수 : {len(train_data)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:57.455379700Z",
     "start_time": "2024-01-31T08:22:57.310378400Z"
    }
   },
   "id": "b1b7ffd6185f0495"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:57.457379500Z",
     "start_time": "2024-01-31T08:22:57.333378Z"
    }
   },
   "id": "fab3de6148d2aba6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 구두점 제거 대신 띄어쓰기를 추가하여 다른 문자와 구분\n",
    "# 정규식 사용하여 처리\n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "    \n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:57.717378Z",
     "start_time": "2024-01-31T08:22:57.375378200Z"
    }
   },
   "id": "5e569086f0191990"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:22:57.728378600Z",
     "start_time": "2024-01-31T08:22:57.525378700Z"
    }
   },
   "id": "a6d84f7f4a7d5b09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[단어 집합 생성]\n",
    "서브워드 텍스트 인코더를 사용하여 서브워드로 구성된 단어 집합 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "442eeffca1a4056d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:05.912014600Z",
     "start_time": "2024-01-31T08:22:57.544379Z"
    }
   },
   "id": "7dab157794c60ab"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:05.927014500Z",
     "start_time": "2024-01-31T08:23:05.913015400Z"
    }
   },
   "id": "dc0b7efa68a0491b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN : [8178]\n",
      "END_TOKEN : [8179]\n",
      "VOCAB_SIZE : 8180\n"
     ]
    }
   ],
   "source": [
    "print(f'START_TOKEN : {START_TOKEN}')\n",
    "print(f'END_TOKEN : {END_TOKEN}')\n",
    "print(f'VOCAB_SIZE : {VOCAB_SIZE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:05.960015300Z",
     "start_time": "2024-01-31T08:23:05.929014900Z"
    }
   },
   "id": "27d2e0326f2df7a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[정수 인코딩과 패딩]\n",
    "토크나이저의 .encode()를 사용하여 정수 인코딩"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccdcb09aadcdc87b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문장 : 가스비 비싼데 감기 걸리겠어\n",
      "encode 후 : [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "decode 후 : 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "sample_string = questions[20]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print(f'원본 문장 : {sample_string}')\n",
    "print(f'encode 후 : {tokenized_string}')\n",
    "print(f'decode 후 : {tokenizer.decode(tokenized_string)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:05.962014200Z",
     "start_time": "2024-01-31T08:23:05.943014300Z"
    }
   },
   "id": "82d3a75bc09c8c10"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "for token in tokenized_string:\n",
    "    print(f'{token} ----> {tokenizer.decode([token])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:06.008015300Z",
     "start_time": "2024-01-31T08:23:05.958015100Z"
    }
   },
   "id": "ddb2af9dbfb700c8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def encode_and_padding(inputs, outputs):\n",
    "    \"\"\"\n",
    "    1. 토크나이저로 인코딩\n",
    "    2. START_TOKEN, END_TOKEN 추가\n",
    "    3. 패딩 수행\n",
    "    \n",
    "    :param inputs: 데이터 셋의 입력\n",
    "    :param outputs: 데이터 셋의 출력\n",
    "    :return: 인코딩된 입력과 출력 리스트\n",
    "    \"\"\"\n",
    "    encoded_inputs, encoded_outputs = [], []\n",
    "    \n",
    "    for input_sentence, output_sentence in zip(inputs, outputs):\n",
    "        encoded_inputs.append(START_TOKEN + tokenizer.encode(input_sentence) + END_TOKEN)\n",
    "        encoded_outputs.append(START_TOKEN + tokenizer.encode(output_sentence) + END_TOKEN)\n",
    "        \n",
    "    encoded_inputs = tf.keras.preprocessing.sequence.pad_sequences(encoded_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    encoded_outputs = tf.keras.preprocessing.sequence.pad_sequences(encoded_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return encoded_inputs, encoded_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:06.009015300Z",
     "start_time": "2024-01-31T08:23:05.974014500Z"
    }
   },
   "id": "b7d4aed515b2df6d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기 : (11823, 40)\n",
      "답변 데이터의 크기 : (11823, 40)\n",
      "0번 샘플 질문 데이터 : [8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "0번 샘플 답변 데이터 : [8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "encoded_questions, encoded_answers = encode_and_padding(questions, answers)\n",
    "\n",
    "print(f'질문 데이터의 크기 : {encoded_questions.shape}')\n",
    "print(f'답변 데이터의 크기 : {encoded_answers.shape}')\n",
    "\n",
    "print(f'0번 샘플 질문 데이터 : {encoded_questions[0]}')\n",
    "print(f'0번 샘플 답변 데이터 : {encoded_answers[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:06.407014100Z",
     "start_time": "2024-01-31T08:23:05.989014500Z"
    }
   },
   "id": "1503d6f3e567810a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[트랜스포머 만들기]\n",
    "인풋 모양은 (2(인코더 입력, 디코더 입력), batch_size, MAX_LENGTH)을 의미"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee0ac562ba43af6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "transformer = Transformer(vocab_size=VOCAB_SIZE,\n",
    "                          d_model=D_MODEL,\n",
    "                          num_layers=NUM_LAYERS,\n",
    "                          num_heads=NUM_HEADS,\n",
    "                          d_ff=DFF,\n",
    "                          dropout=DROPOUT)\n",
    "\n",
    "transformer.build(input_shape=(2, BATCH_SIZE, MAX_LENGTH))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:07.127014200Z",
     "start_time": "2024-01-31T08:23:06.409015400Z"
    }
   },
   "id": "65cfdf93573fa88b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "learning_rate = TransformerScheduler(d_model=D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "transformer.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:23:07.159014200Z",
     "start_time": "2024-01-31T08:23:07.128015800Z"
    }
   },
   "id": "20c08a207af4361c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 61s 245ms/step - loss: 1.5455 - accuracy: 0.0015\n",
      "Epoch 2/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 1.3615 - accuracy: 0.0328\n",
      "Epoch 3/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 1.1254 - accuracy: 0.0456\n",
      "Epoch 4/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 1.0149 - accuracy: 0.0494\n",
      "Epoch 5/60\n",
      "185/185 [==============================] - 45s 243ms/step - loss: 0.9372 - accuracy: 0.0522\n",
      "Epoch 6/60\n",
      "185/185 [==============================] - 45s 246ms/step - loss: 0.8824 - accuracy: 0.0561\n",
      "Epoch 7/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.8300 - accuracy: 0.0598\n",
      "Epoch 8/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.7735 - accuracy: 0.0650\n",
      "Epoch 9/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.7127 - accuracy: 0.0710\n",
      "Epoch 10/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.6495 - accuracy: 0.0780\n",
      "Epoch 11/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.5861 - accuracy: 0.0854\n",
      "Epoch 12/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.5241 - accuracy: 0.0929\n",
      "Epoch 13/60\n",
      "185/185 [==============================] - 45s 245ms/step - loss: 0.4653 - accuracy: 0.1005\n",
      "Epoch 14/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.4093 - accuracy: 0.1084\n",
      "Epoch 15/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.3573 - accuracy: 0.1156\n",
      "Epoch 16/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.3088 - accuracy: 0.1236\n",
      "Epoch 17/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.2644 - accuracy: 0.1307\n",
      "Epoch 18/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.2254 - accuracy: 0.1371\n",
      "Epoch 19/60\n",
      "185/185 [==============================] - 46s 246ms/step - loss: 0.1901 - accuracy: 0.1429\n",
      "Epoch 20/60\n",
      "185/185 [==============================] - 45s 243ms/step - loss: 0.1601 - accuracy: 0.1484\n",
      "Epoch 21/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.1341 - accuracy: 0.1527\n",
      "Epoch 22/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.1123 - accuracy: 0.1567\n",
      "Epoch 23/60\n",
      "185/185 [==============================] - 44s 240ms/step - loss: 0.0928 - accuracy: 0.1602\n",
      "Epoch 24/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0767 - accuracy: 0.1634\n",
      "Epoch 25/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0641 - accuracy: 0.1654\n",
      "Epoch 26/60\n",
      "185/185 [==============================] - 46s 247ms/step - loss: 0.0538 - accuracy: 0.1675\n",
      "Epoch 27/60\n",
      "185/185 [==============================] - 45s 243ms/step - loss: 0.0458 - accuracy: 0.1688\n",
      "Epoch 28/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0399 - accuracy: 0.1696\n",
      "Epoch 29/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0349 - accuracy: 0.1703\n",
      "Epoch 30/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0308 - accuracy: 0.1709\n",
      "Epoch 31/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0276 - accuracy: 0.1715\n",
      "Epoch 32/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0250 - accuracy: 0.1719\n",
      "Epoch 33/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0226 - accuracy: 0.1722\n",
      "Epoch 34/60\n",
      "185/185 [==============================] - 45s 243ms/step - loss: 0.0208 - accuracy: 0.1724\n",
      "Epoch 35/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0194 - accuracy: 0.1726\n",
      "Epoch 36/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0183 - accuracy: 0.1727\n",
      "Epoch 37/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0170 - accuracy: 0.1729\n",
      "Epoch 38/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0158 - accuracy: 0.1730\n",
      "Epoch 39/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0152 - accuracy: 0.1731\n",
      "Epoch 40/60\n",
      "185/185 [==============================] - 45s 243ms/step - loss: 0.0143 - accuracy: 0.1733\n",
      "Epoch 41/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0135 - accuracy: 0.1734\n",
      "Epoch 42/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0132 - accuracy: 0.1734\n",
      "Epoch 43/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0125 - accuracy: 0.1735\n",
      "Epoch 44/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0124 - accuracy: 0.1735\n",
      "Epoch 45/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0120 - accuracy: 0.1735\n",
      "Epoch 46/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0116 - accuracy: 0.1736\n",
      "Epoch 47/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0110 - accuracy: 0.1737\n",
      "Epoch 48/60\n",
      "185/185 [==============================] - 45s 245ms/step - loss: 0.0106 - accuracy: 0.1737\n",
      "Epoch 49/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0100 - accuracy: 0.1738\n",
      "Epoch 50/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0097 - accuracy: 0.1739\n",
      "Epoch 51/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0094 - accuracy: 0.1739\n",
      "Epoch 52/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0090 - accuracy: 0.1739\n",
      "Epoch 53/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0088 - accuracy: 0.1739\n",
      "Epoch 54/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0085 - accuracy: 0.1739\n",
      "Epoch 55/60\n",
      "185/185 [==============================] - 45s 244ms/step - loss: 0.0080 - accuracy: 0.1740\n",
      "Epoch 56/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0081 - accuracy: 0.1740\n",
      "Epoch 57/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0077 - accuracy: 0.1741\n",
      "Epoch 58/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0074 - accuracy: 0.1741\n",
      "Epoch 59/60\n",
      "185/185 [==============================] - 45s 241ms/step - loss: 0.0073 - accuracy: 0.1741\n",
      "Epoch 60/60\n",
      "185/185 [==============================] - 45s 242ms/step - loss: 0.0071 - accuracy: 0.1742\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x226269af700>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "transformer.fit(x=(encoded_questions, encoded_answers[:, :-1]), y=encoded_answers[:, 1:], batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:08:09.754854600Z",
     "start_time": "2024-01-31T08:23:07.158014800Z"
    }
   },
   "id": "bca300be0d49e65c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[평가]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16fe8e7428c7f649"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:08:09.785853800Z",
     "start_time": "2024-01-31T09:08:09.754854600Z"
    }
   },
   "id": "b7614f8ecc82a060"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    print(sentence)\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = transformer.predict((sentence, output), verbose=0)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        \n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "            \n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        \n",
    "    return tf.squeeze(output, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:08:09.786855200Z",
     "start_time": "2024-01-31T09:08:09.770854400Z"
    }
   },
   "id": "2d57068a0ba935e1",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "    \n",
    "    print(f'Input: {sentence}')\n",
    "    print(f'Output: {predicted_sentence}')\n",
    "    \n",
    "    return predicted_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:08:09.806855200Z",
     "start_time": "2024-01-31T09:08:09.784854Z"
    }
   },
   "id": "cd5b99a16741e9ff",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부 하기 싫어\n",
      "Input: 공부 하기 싫어\n",
      "Output: 거리를 걸어보세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"공부 하기 싫어\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:08:13.577854900Z",
     "start_time": "2024-01-31T09:08:12.664856100Z"
    }
   },
   "id": "22ba827effc2d2ad",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "게임하고 싶어\n",
      "Input: 게임하고 싶어\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고 싶어\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T09:08:13.773853500Z",
     "start_time": "2024-01-31T09:08:13.578854900Z"
    }
   },
   "id": "6f3006ab18fbb64d",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 랩장은 누구일까요?\n",
      "Input: 다음 랩장은 누구일까요?\n",
      "Output: 계획 세우고 하세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"다음 랩장은 누구일까요?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T11:20:39.613729900Z",
     "start_time": "2024-01-31T11:20:39.304731900Z"
    }
   },
   "id": "1aec5657512af54e",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea2a0ef2c63e8104"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
