{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:24.676694700Z",
     "start_time": "2024-01-27T12:02:14.151401900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han SeongMin\\AppData\\Local\\Temp\\ipykernel_10992\\3242935675.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Han SeongMin\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from transformer import Transformer\n",
    "from scheduler import TransformerScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[손실 함수 정의]\n",
    "예제는 다중 클래스 분류 문제. 이때 레이블이 정수 형태이므로 손실 함수는 SparseCategoricalCrossentropy 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576a91a72ec088d6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def loss_function(ans, pred):\n",
    "    \"\"\"\n",
    "    다중 클래스 분류 문제를 위한 손실 함수 정의\n",
    "    \n",
    "    :param ans: 해당 데이터의 실제 정답\n",
    "    :param pred: 모델이 생성해낸 예측 레이블\n",
    "    :return: 손실값\n",
    "    \"\"\"\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(ans, pred)\n",
    "    mask = tf.cast(tf.not_equal(ans, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:24.693997Z",
     "start_time": "2024-01-27T12:02:24.681693Z"
    }
   },
   "id": "83f963a7f2de3c71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[데이터 로드]\n",
    "챗봇 데이터를 로드\n",
    "학습 기반 토크나이저 사용을 위해 구두점 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2feef9c408aadea0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Q            A  label\n0           12시 땡!   하루가 또 가네요.      0\n1      1지망 학교 떨어졌어    위로해 드립니다.      0\n2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n4          PPL 심하네   눈살이 찌푸려지죠.      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Q</th>\n      <th>A</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12시 땡!</td>\n      <td>하루가 또 가네요.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1지망 학교 떨어졌어</td>\n      <td>위로해 드립니다.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3박4일 놀러가고 싶다</td>\n      <td>여행은 언제나 좋죠.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3박4일 정도 놀러가고 싶다</td>\n      <td>여행은 언제나 좋죠.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PPL 심하네</td>\n      <td>눈살이 찌푸려지죠.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('CHatBotData.csv')\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:25.181550300Z",
     "start_time": "2024-01-27T12:02:24.693997Z"
    }
   },
   "id": "1650b7db4acef3b9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print(f'샘플의 개수 : {len(train_data)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:25.198267900Z",
     "start_time": "2024-01-27T12:02:25.174529300Z"
    }
   },
   "id": "b1b7ffd6185f0495"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:25.228045100Z",
     "start_time": "2024-01-27T12:02:25.190014Z"
    }
   },
   "id": "fab3de6148d2aba6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 구두점 제거 대신 띄어쓰기를 추가하여 다른 문자와 구분\n",
    "# 정규식 사용하여 처리\n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "    \n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:25.362084400Z",
     "start_time": "2024-01-27T12:02:25.206521300Z"
    }
   },
   "id": "5e569086f0191990"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:25.364080600Z",
     "start_time": "2024-01-27T12:02:25.297617100Z"
    }
   },
   "id": "a6d84f7f4a7d5b09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[단어 집합 생성]\n",
    "서브워드 텍스트 인코더를 사용하여 서브워드로 구성된 단어 집합 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "442eeffca1a4056d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:38.176535Z",
     "start_time": "2024-01-27T12:02:25.313642500Z"
    }
   },
   "id": "7dab157794c60ab"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:38.193135500Z",
     "start_time": "2024-01-27T12:02:38.178593900Z"
    }
   },
   "id": "dc0b7efa68a0491b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN : [8178]\n",
      "END_TOKEN : [8179]\n",
      "VOCAB_SIZE : 8180\n"
     ]
    }
   ],
   "source": [
    "print(f'START_TOKEN : {START_TOKEN}')\n",
    "print(f'END_TOKEN : {END_TOKEN}')\n",
    "print(f'VOCAB_SIZE : {VOCAB_SIZE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:38.247451900Z",
     "start_time": "2024-01-27T12:02:38.191048600Z"
    }
   },
   "id": "27d2e0326f2df7a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[정수 인코딩과 패딩]\n",
    "토크나이저의 .encode()를 사용하여 정수 인코딩"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccdcb09aadcdc87b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문장 : 가스비 비싼데 감기 걸리겠어\n",
      "encode 후 : [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "decode 후 : 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "sample_string = questions[20]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print(f'원본 문장 : {sample_string}')\n",
    "print(f'encode 후 : {tokenized_string}')\n",
    "print(f'decode 후 : {tokenizer.decode(tokenized_string)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:38.281564500Z",
     "start_time": "2024-01-27T12:02:38.206002900Z"
    }
   },
   "id": "82d3a75bc09c8c10"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "for token in tokenized_string:\n",
    "    print(f'{token} ----> {tokenizer.decode([token])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:38.282064700Z",
     "start_time": "2024-01-27T12:02:38.222076900Z"
    }
   },
   "id": "ddb2af9dbfb700c8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def encode_and_padding(inputs, outputs):\n",
    "    \"\"\"\n",
    "    1. 토크나이저로 인코딩\n",
    "    2. START_TOKEN, END_TOKEN 추가\n",
    "    3. 패딩 수행\n",
    "    \n",
    "    :param inputs: 데이터 셋의 입력\n",
    "    :param outputs: 데이터 셋의 출력\n",
    "    :return: 인코딩된 입력과 출력 리스트\n",
    "    \"\"\"\n",
    "    encoded_inputs, encoded_outputs = [], []\n",
    "    \n",
    "    for input_sentence, output_sentence in zip(inputs, outputs):\n",
    "        encoded_inputs.append(START_TOKEN + tokenizer.encode(input_sentence) + END_TOKEN)\n",
    "        encoded_outputs.append(START_TOKEN + tokenizer.encode(output_sentence) + END_TOKEN)\n",
    "        \n",
    "    encoded_inputs = tf.keras.preprocessing.sequence.pad_sequences(encoded_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    encoded_outputs = tf.keras.preprocessing.sequence.pad_sequences(encoded_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return encoded_inputs, encoded_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:38.338059400Z",
     "start_time": "2024-01-27T12:02:38.242132800Z"
    }
   },
   "id": "b7d4aed515b2df6d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기 : (11823, 40)\n",
      "답변 데이터의 크기 : (11823, 40)\n",
      "0번 샘플 질문 데이터 : [8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "0번 샘플 답변 데이터 : [8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "encoded_questions, encoded_answers = encode_and_padding(questions, answers)\n",
    "\n",
    "print(f'질문 데이터의 크기 : {encoded_questions.shape}')\n",
    "print(f'답변 데이터의 크기 : {encoded_answers.shape}')\n",
    "\n",
    "print(f'0번 샘플 질문 데이터 : {encoded_questions[0]}')\n",
    "print(f'0번 샘플 답변 데이터 : {encoded_answers[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:39.028408400Z",
     "start_time": "2024-01-27T12:02:38.254654900Z"
    }
   },
   "id": "1503d6f3e567810a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[인코더와 디코더의 입력 및 레이블 만들기]\n",
    "tf.data.Dataset을 사용하여 데이터를 배치 단위로 불러올 수 있다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e758ba130ff71b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'inputs': encoded_questions,\n",
    "    'dec_inputs': encoded_answers[:, :-1]\n",
    "},\n",
    "{\n",
    "    'outputs': encoded_answers[:, 1:]\n",
    "}))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:39.106526900Z",
     "start_time": "2024-01-27T12:02:39.029418800Z"
    }
   },
   "id": "2e30d75efe9f2f09"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'inputs': <tf.Tensor: shape=(64, 40), dtype=int32, numpy=\n",
      "array([[8178,   51,  371, ...,    0,    0,    0],\n",
      "       [8178, 4099,  354, ...,    0,    0,    0],\n",
      "       [8178,  618,  258, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [8178, 1096,  350, ...,    0,    0,    0],\n",
      "       [8178,  882,  220, ...,    0,    0,    0],\n",
      "       [8178,  770,  782, ...,    0,    0,    0]])>, 'dec_inputs': <tf.Tensor: shape=(64, 39), dtype=int32, numpy=\n",
      "array([[8178,   51,  371, ...,    0,    0,    0],\n",
      "       [8178,  656, 5311, ...,    0,    0,    0],\n",
      "       [8178, 7457,    1, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [8178, 1655, 5317, ...,    0,    0,    0],\n",
      "       [8178, 4509,   25, ...,    0,    0,    0],\n",
      "       [8178, 7690,  906, ...,    0,    0,    0]])>}, {'outputs': <tf.Tensor: shape=(64, 39), dtype=int32, numpy=\n",
      "array([[  51,  371,  174, ...,    0,    0,    0],\n",
      "       [ 656, 5311,    5, ...,    0,    0,    0],\n",
      "       [7457,    1, 8179, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [1655, 5317, 2528, ...,    0,    0,    0],\n",
      "       [4509,   25,    1, ...,    0,    0,    0],\n",
      "       [7690,  906,   92, ...,    0,    0,    0]])>})\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:39.189169700Z",
     "start_time": "2024-01-27T12:02:39.111628600Z"
    }
   },
   "id": "a6e6b1d59e1d727e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[트랜스포머 만들기]\n",
    "인풋 모양은 (2(인코더 입력, 디코더 입력), batch_size, MAX_LENGTH)을 의미"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee0ac562ba43af6"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Han SeongMin\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Han SeongMin\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Han SeongMin\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Han SeongMin\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).\n\nThe actual error from `call` is: 'SymbolicTensor' object cannot be interpreted as an integer.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:542\u001B[0m, in \u001B[0;36mModel.build\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 542\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (tf\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mInvalidArgumentError, \u001B[38;5;167;01mTypeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\KIT-Transformer\\src\\transformer.py:41\u001B[0m, in \u001B[0;36mTransformer.call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m     40\u001B[0m encoder_inputs \u001B[38;5;241m=\u001B[39m embedding(inputs\u001B[38;5;241m=\u001B[39mencoder_inputs, vocab_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size, d_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model)\n\u001B[1;32m---> 41\u001B[0m encoder_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mpositional_encoding\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mposition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_inputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43md_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder\u001B[38;5;241m.\u001B[39mencode(inputs\u001B[38;5;241m=\u001B[39mencoder_inputs, pad_mask\u001B[38;5;241m=\u001B[39mencoder_mask)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KIT-Transformer\\src\\modules\\positional_encoder.py:52\u001B[0m, in \u001B[0;36mpositional_encoding\u001B[1;34m(inputs, position, d_model, dropout)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;124;03m임베딩 행렬을 입력받아 포지셔널 인코딩 행렬을 더하여 인코더, 디코더의 입력으로 사용할 수 있는 임베딩 행렬 반환\u001B[39;00m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;124;03m기본적으로 드롭아웃은 서브층 이후에 적용되지만 예외적으로 임베딩 벡터 + 포지셔널 인코딩 작업 이후에도 적용\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;124;03m:return: 포지셔널 인코딩 행렬이 더해진 임베딩 행렬\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m inputs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43m_get_positional_encode_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposition\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Dropout(rate\u001B[38;5;241m=\u001B[39mdropout)(inputs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KIT-Transformer\\src\\modules\\positional_encoder.py:32\u001B[0m, in \u001B[0;36m_get_positional_encode_matrix\u001B[1;34m(position, d_model)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;124;03m트랜스포머에게 단어의 위치 정보를 주입하는 포지셔널 인코딩 행렬을 계산 / 반환\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m:return: 포지셔널 인코딩 행렬\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m positional_encode_vector \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposition\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_model\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pos, row_vector \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(positional_encode_vector):\n",
      "\u001B[1;31mTypeError\u001B[0m: 'SymbolicTensor' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 14\u001B[0m\n\u001B[0;32m      5\u001B[0m DROPOUT \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m\n\u001B[0;32m      7\u001B[0m transformer \u001B[38;5;241m=\u001B[39m Transformer(vocab_size\u001B[38;5;241m=\u001B[39mVOCAB_SIZE,\n\u001B[0;32m      8\u001B[0m                           d_model\u001B[38;5;241m=\u001B[39mD_MODEL,\n\u001B[0;32m      9\u001B[0m                           num_layers\u001B[38;5;241m=\u001B[39mNUM_LAYERS,\n\u001B[0;32m     10\u001B[0m                           num_heads\u001B[38;5;241m=\u001B[39mNUM_HEADS,\n\u001B[0;32m     11\u001B[0m                           d_ff\u001B[38;5;241m=\u001B[39mDFF,\n\u001B[0;32m     12\u001B[0m                           dropout\u001B[38;5;241m=\u001B[39mDROPOUT)\n\u001B[1;32m---> 14\u001B[0m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMAX_LENGTH\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KIT-Transformer\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:544\u001B[0m, in \u001B[0;36mModel.build\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m    542\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    543\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m (tf\u001B[38;5;241m.\u001B[39merrors\u001B[38;5;241m.\u001B[39mInvalidArgumentError, \u001B[38;5;167;01mTypeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 544\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    545\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot build your model by calling `build` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    546\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif your layers do not support float type inputs. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    547\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstead, in order to instantiate and build your \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    548\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel, call your model on real tensor data (of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    549\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe correct dtype).\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mThe actual error from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    550\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`call` is: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    551\u001B[0m             )\n\u001B[0;32m    552\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mbuild(input_shape)\n",
      "\u001B[1;31mValueError\u001B[0m: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).\n\nThe actual error from `call` is: 'SymbolicTensor' object cannot be interpreted as an integer."
     ]
    }
   ],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "transformer = Transformer(vocab_size=VOCAB_SIZE,\n",
    "                          d_model=D_MODEL,\n",
    "                          num_layers=NUM_LAYERS,\n",
    "                          num_heads=NUM_HEADS,\n",
    "                          d_ff=DFF,\n",
    "                          dropout=DROPOUT)\n",
    "\n",
    "transformer.build(input_shape=(2, BATCH_SIZE, MAX_LENGTH))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T12:02:40.231568500Z",
     "start_time": "2024-01-27T12:02:39.189169700Z"
    }
   },
   "id": "65cfdf93573fa88b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = TransformerScheduler(d_model=D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, (-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "transformer.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-27T12:02:40.214251200Z"
    }
   },
   "id": "20c08a207af4361c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "transformer.fit(dataset, epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-27T12:02:40.221566200Z"
    }
   },
   "id": "bca300be0d49e65c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-27T12:02:40.227568800Z"
    }
   },
   "id": "b7614f8ecc82a060"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
