{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:25.350171900Z",
     "start_time": "2024-01-28T13:35:20.003171900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wintee\\AppData\\Local\\Temp\\ipykernel_1856\\3242935675.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from transformer import Transformer\n",
    "from scheduler import TransformerScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[손실 함수 정의]\n",
    "예제는 다중 클래스 분류 문제. 이때 레이블이 정수 형태이므로 손실 함수는 SparseCategoricalCrossentropy 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576a91a72ec088d6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def loss_function(ans, pred):\n",
    "    \"\"\"\n",
    "    다중 클래스 분류 문제를 위한 손실 함수 정의\n",
    "    \n",
    "    :param ans: 해당 데이터의 실제 정답\n",
    "    :param pred: 모델이 생성해낸 예측 레이블\n",
    "    :return: 손실값\n",
    "    \"\"\"\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(ans, pred)\n",
    "    mask = tf.cast(tf.not_equal(ans, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:25.365171400Z",
     "start_time": "2024-01-28T13:35:25.350171900Z"
    }
   },
   "id": "83f963a7f2de3c71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[데이터 로드]\n",
    "챗봇 데이터를 로드\n",
    "학습 기반 토크나이저 사용을 위해 구두점 처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2feef9c408aadea0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Q            A  label\n0           12시 땡!   하루가 또 가네요.      0\n1      1지망 학교 떨어졌어    위로해 드립니다.      0\n2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n4          PPL 심하네   눈살이 찌푸려지죠.      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Q</th>\n      <th>A</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12시 땡!</td>\n      <td>하루가 또 가네요.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1지망 학교 떨어졌어</td>\n      <td>위로해 드립니다.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3박4일 놀러가고 싶다</td>\n      <td>여행은 언제나 좋죠.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3박4일 정도 놀러가고 싶다</td>\n      <td>여행은 언제나 좋죠.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PPL 심하네</td>\n      <td>눈살이 찌푸려지죠.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:25.995171300Z",
     "start_time": "2024-01-28T13:35:25.365171400Z"
    }
   },
   "id": "1650b7db4acef3b9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print(f'샘플의 개수 : {len(train_data)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:26.020171900Z",
     "start_time": "2024-01-28T13:35:25.995171300Z"
    }
   },
   "id": "b1b7ffd6185f0495"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:26.043171500Z",
     "start_time": "2024-01-28T13:35:26.010172800Z"
    }
   },
   "id": "fab3de6148d2aba6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 구두점 제거 대신 띄어쓰기를 추가하여 다른 문자와 구분\n",
    "# 정규식 사용하여 처리\n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "    \n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:26.113171500Z",
     "start_time": "2024-01-28T13:35:26.026171400Z"
    }
   },
   "id": "5e569086f0191990"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:26.139171900Z",
     "start_time": "2024-01-28T13:35:26.101172300Z"
    }
   },
   "id": "a6d84f7f4a7d5b09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[단어 집합 생성]\n",
    "서브워드 텍스트 인코더를 사용하여 서브워드로 구성된 단어 집합 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "442eeffca1a4056d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.541171900Z",
     "start_time": "2024-01-28T13:35:26.116171600Z"
    }
   },
   "id": "7dab157794c60ab"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.555172300Z",
     "start_time": "2024-01-28T13:35:33.541171900Z"
    }
   },
   "id": "dc0b7efa68a0491b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN : [8178]\n",
      "END_TOKEN : [8179]\n",
      "VOCAB_SIZE : 8180\n"
     ]
    }
   ],
   "source": [
    "print(f'START_TOKEN : {START_TOKEN}')\n",
    "print(f'END_TOKEN : {END_TOKEN}')\n",
    "print(f'VOCAB_SIZE : {VOCAB_SIZE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.585173Z",
     "start_time": "2024-01-28T13:35:33.556173800Z"
    }
   },
   "id": "27d2e0326f2df7a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[정수 인코딩과 패딩]\n",
    "토크나이저의 .encode()를 사용하여 정수 인코딩"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccdcb09aadcdc87b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문장 : 가스비 비싼데 감기 걸리겠어\n",
      "encode 후 : [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "decode 후 : 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "sample_string = questions[20]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print(f'원본 문장 : {sample_string}')\n",
    "print(f'encode 후 : {tokenized_string}')\n",
    "print(f'decode 후 : {tokenizer.decode(tokenized_string)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.587171300Z",
     "start_time": "2024-01-28T13:35:33.572170800Z"
    }
   },
   "id": "82d3a75bc09c8c10"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "for token in tokenized_string:\n",
    "    print(f'{token} ----> {tokenizer.decode([token])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.626171400Z",
     "start_time": "2024-01-28T13:35:33.587171300Z"
    }
   },
   "id": "ddb2af9dbfb700c8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def encode_and_padding(inputs, outputs):\n",
    "    \"\"\"\n",
    "    1. 토크나이저로 인코딩\n",
    "    2. START_TOKEN, END_TOKEN 추가\n",
    "    3. 패딩 수행\n",
    "    \n",
    "    :param inputs: 데이터 셋의 입력\n",
    "    :param outputs: 데이터 셋의 출력\n",
    "    :return: 인코딩된 입력과 출력 리스트\n",
    "    \"\"\"\n",
    "    encoded_inputs, encoded_outputs = [], []\n",
    "    \n",
    "    for input_sentence, output_sentence in zip(inputs, outputs):\n",
    "        encoded_inputs.append(START_TOKEN + tokenizer.encode(input_sentence) + END_TOKEN)\n",
    "        encoded_outputs.append(START_TOKEN + tokenizer.encode(output_sentence) + END_TOKEN)\n",
    "        \n",
    "    encoded_inputs = tf.keras.preprocessing.sequence.pad_sequences(encoded_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    encoded_outputs = tf.keras.preprocessing.sequence.pad_sequences(encoded_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return encoded_inputs, encoded_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.627170800Z",
     "start_time": "2024-01-28T13:35:33.603171900Z"
    }
   },
   "id": "b7d4aed515b2df6d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기 : (11823, 40)\n",
      "답변 데이터의 크기 : (11823, 40)\n",
      "0번 샘플 질문 데이터 : [8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "0번 샘플 답변 데이터 : [8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "encoded_questions, encoded_answers = encode_and_padding(questions, answers)\n",
    "\n",
    "print(f'질문 데이터의 크기 : {encoded_questions.shape}')\n",
    "print(f'답변 데이터의 크기 : {encoded_answers.shape}')\n",
    "\n",
    "print(f'0번 샘플 질문 데이터 : {encoded_questions[0]}')\n",
    "print(f'0번 샘플 답변 데이터 : {encoded_answers[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:33.903172200Z",
     "start_time": "2024-01-28T13:35:33.618170800Z"
    }
   },
   "id": "1503d6f3e567810a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[트랜스포머 만들기]\n",
    "인풋 모양은 (2(인코더 입력, 디코더 입력), batch_size, MAX_LENGTH)을 의미"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee0ac562ba43af6"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "transformer = Transformer(vocab_size=VOCAB_SIZE,\n",
    "                          d_model=D_MODEL,\n",
    "                          num_layers=NUM_LAYERS,\n",
    "                          num_heads=NUM_HEADS,\n",
    "                          d_ff=DFF,\n",
    "                          dropout=DROPOUT)\n",
    "\n",
    "transformer.build(input_shape=(2, BATCH_SIZE, MAX_LENGTH))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:34.561171700Z",
     "start_time": "2024-01-28T13:35:33.992171600Z"
    }
   },
   "id": "65cfdf93573fa88b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "learning_rate = TransformerScheduler(d_model=D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "transformer.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:34.597173800Z",
     "start_time": "2024-01-28T13:35:34.561171700Z"
    }
   },
   "id": "20c08a207af4361c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\wintee\\AppData\\Local\\Temp\\__autograph_generated_filewgyk1qg_.py\", line 10, in tf__call\n        encoder_inputs = ag__.ld(inputs)[0]\n\n    RuntimeError: Exception encountered when calling layer 'transformer' (type Transformer).\n    \n    KeyError: 0\n    \n    Call arguments received by layer 'transformer' (type Transformer):\n      • inputs={'inputs': 'tf.Tensor(shape=(None, 40), dtype=int32)', 'dec_inputs': 'tf.Tensor(shape=(None, 39), dtype=int32)'}\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m EPOCHS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file4gvibfp_.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewgyk1qg_.py:10\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m      8\u001B[0m do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m      9\u001B[0m retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefinedReturnValue()\n\u001B[1;32m---> 10\u001B[0m encoder_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     11\u001B[0m decoder_inputs \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(inputs)[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     12\u001B[0m encoder_position \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(encoder_inputs)\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mRuntimeError\u001B[0m: in user code:\n\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\wintee\\PycharmProjects\\KIT-Transformer\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\wintee\\AppData\\Local\\Temp\\__autograph_generated_filewgyk1qg_.py\", line 10, in tf__call\n        encoder_inputs = ag__.ld(inputs)[0]\n\n    RuntimeError: Exception encountered when calling layer 'transformer' (type Transformer).\n    \n    KeyError: 0\n    \n    Call arguments received by layer 'transformer' (type Transformer):\n      • inputs={'inputs': 'tf.Tensor(shape=(None, 40), dtype=int32)', 'dec_inputs': 'tf.Tensor(shape=(None, 39), dtype=int32)'}\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "transformer.fit(x=(encoded_questions, encoded_answers), y=encoded_answers, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:35.025171500Z",
     "start_time": "2024-01-28T13:35:34.591172Z"
    }
   },
   "id": "bca300be0d49e65c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:35:35.032171200Z",
     "start_time": "2024-01-28T13:35:35.027172100Z"
    }
   },
   "id": "b7614f8ecc82a060"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
